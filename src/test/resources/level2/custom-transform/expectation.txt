word
apache
hadoop
is
an
open-source
software
framework
that
supports
data-intensive
distributed
applications,
licensed
under
the
apache
v2
license.
it
supports
the
running
of
applications
on
large
clusters
of
commodity
hardware.
the
hadoop
framework
transparently
provides
both
reliability
and
data
motion
to
applications.
hadoop
implements
a
computational
paradigm
named
map/reduce,
where
the
application
is
divided
into
many
small
fragments
of
work,
each
of
which
may
be
executed
or
re-executed
on
any
node
in
the
cluster.
in
addition,
it
provides
a
distributed
file
system
that
stores
data
on
the
compute
nodes,
providing
very
high
aggregate
bandwidth
across
the
cluster.
both
map/reduce
and
the
distributed
file
system
are
designed
so
that
node
failures
are
automatically
handled
by
the
framework.[1]
it
enables
applications
to
work
with
thousands
of
computation-independent
computers
and
petabytes
of
data.
hadoop
was
derived
from
google's
mapreduce
and
google
file
system
(gfs)
papers.
